# ğŸ§ª Glass Classification Using Random Forest, Bagging & Boosting

A complete end-to-end Machine Learning pipeline built in Python to classify glass types using the **UCI Glass Identification Dataset**.  
This project includes **EDA, data cleaning, preprocessing, visualizations, Random Forest model training, Bagging/Boosting, and detailed performance reports**.

---

## â­ Project Highlights

- âœ” Fully automated ML pipeline (no Jupyter Notebook required)  
- âœ” Auto-cleaning of messy Excel data (skips textual description rows)  
- âœ” Exploratory Data Analysis + automated EDA text report  
- âœ” Visualizations (histograms, boxplots, correlation heatmaps)  
- âœ” Preprocessing (duplicate removal, scaling, SMOTE oversampling)  
- âœ” Machine Learning:
  - ğŸŒ³ **Random Forest Classifier**
  - ğŸ§º **Bagging Classifier**
  - ğŸš€ **AdaBoost Classifier**
- âœ” Model saving (`.pkl` format)  
- âœ” Logging + time tracking  
- âœ” Fully modular & production-ready folder structure  

---

## ğŸ“‚ Project Structure

```
Glass-RandomForest-Project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # (MANUAL) Place glass.xlsx here
â”‚   â”‚   â””â”€â”€ glass.xlsx
â”‚   â””â”€â”€ processed/              # (AUTO) cleaned_glass.csv saved here
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py            # Load & clean raw data
â”‚   â”œâ”€â”€ eda.py                  # Exploratory Data Analysis
â”‚   â”œâ”€â”€ visualize.py            # Histograms, boxplots, heatmaps
â”‚   â”œâ”€â”€ preprocess.py           # Scaling, SMOTE, cleaning
â”‚   â”œâ”€â”€ train_random_forest.py  # Train Random Forest model
â”‚   â”œâ”€â”€ bagging_boosting.py     # Bagging & AdaBoost models
â”‚   â”œâ”€â”€ evaluate.py             # Reusable evaluation module
â”‚   â”œâ”€â”€ utils.py                # Logging, timers, folder handling
â”‚   â””â”€â”€ main.py                 # MASTER PIPELINE CONTROLLER
â”‚
â”œâ”€â”€ models/                     # (AUTO) Saved ML models
â”‚
â”œâ”€â”€ reports/                    # (AUTO) EDA + model performance reports
â”‚
â”œâ”€â”€ outputs/                    # (AUTO) Generated plots
â”‚   â”œâ”€â”€ histograms/
â”‚   â”œâ”€â”€ boxplots/
â”‚   â””â”€â”€ heatmaps/
â”‚
â”œâ”€â”€ logs/                       # (AUTO) Pipeline logs
â”‚
â”œâ”€â”€ requirements.txt            # Required Python packages
â”‚
â””â”€â”€ README.md                   # (THIS DOCUMENT)
```

---

## ğŸ“Š Dataset Description (UCI Glass Identification)

The dataset contains **chemical analysis of glass samples**, used for forensics.

| Feature | Description |
|---------|-------------|
| RI | Refractive Index |
| Na | Sodium |
| Mg | Magnesium |
| Al | Aluminum |
| Si | Silicon |
| K  | Potassium |
| Ca | Calcium |
| Ba | Barium |
| Fe | Iron |
| Type | Glass class label (1â€“7) |

**Classes include:**
- Building windows (float, non-float)
- Vehicle windows
- Containers
- Tableware
- Headlamps

---

## ğŸ›  Installation

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Place your dataset here:**
```
data/raw/glass.xlsx
```

---

## â–¶ï¸ Running the Full Pipeline

Run this single command:

```bash
python src/main.py
```

**This performs:**

1. Load raw data  
2. Clean data  
3. EDA + text report  
4. Visualizations (saved in outputs/)  
5. Preprocessing (SMOTE + scaling)  
6. Random Forest training  
7. Bagging & Boosting training  
8. Save all models & reports  

---

## ğŸ“ˆ Model Performance Summary

### ğŸŒ³ Random Forest
```
Accuracy:  0.913
Precision: 0.913
Recall:    0.913
F1-score:  0.913
```

### ğŸ§º Bagging Classifier
```
Accuracy:  0.880
Precision: 0.877
Recall:    0.880
F1-score:  0.878
```

### ğŸš€ AdaBoost Classifier
```
Accuracy:  0.445
Precision: 0.366
Recall:    0.445
F1-score:  0.389
```

**Key Findings:**
- â¡ **Random Forest performed the best**  
- â¡ Bagging is reliable  
- â¡ AdaBoost performs poorly due to overlapping class boundaries

---

## ğŸ“Š Visual Outputs

Generated automatically inside `outputs/`:

- Histograms  
- Boxplots  
- Correlation heatmap  

These help understand feature distributions and relationships.

---

## ğŸ“ Reports Generated

Inside `reports/` you get:

- `eda_report.txt`  
- `model_performance.txt`  
- `comparison_results.txt`  

Perfect for academic submission or project documentation.

---

## ğŸš€ Future Improvements

You can extend the project by adding:

- Gradient Boosting / XGBoost / LightGBM  
- Streamlit web app for live predictions  
- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)  
- Confusion matrix visuals  
- Feature importance plots  

---



## ğŸ“„ License

This project is open-source and available under the MIT License.

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

---

## â­ Show your support

Give a â­ï¸ if this project helped you!