# ğŸ“˜ Titanic ML Pipeline â€” EDA â†’ Preprocessing â†’ LightGBM & XGBoost

## ğŸŒŸ Introduction

This project implements a complete, automated Machine Learning pipeline on the classic Titanic Survival Prediction dataset. The pipeline covers every stage of a real-world ML workflow:

âœ” Data loading  
âœ” Exploratory Data Analysis (EDA)  
âœ” Preprocessing  
âœ” Model training (LightGBM & XGBoost)  
âœ” Model evaluation & comparison  
âœ” Saving models, graphs, and reports  
âœ” Fully automated using a single command

The goal is to provide a clean, modular, and industry-style ML architecture suitable for:

* Learning Machine Learning
* Demonstrating portfolio projects
* Kaggle-style competitions
* Academic or research submissions

---

## ğŸ§© Features

### ğŸ” EDA (Exploratory Data Analysis)

The pipeline automatically generates visual insights:

* Age distribution
* Fare distribution
* Survival count
* Survival by gender
* Fare by passenger class

All plots are saved in:

```
output/graphs/
```

### ğŸ§¼ Data Preprocessing

The preprocessing pipeline handles:

* Missing values (Age, Fare, Embarked)
* Dropping high-missing features (Cabin)
* Encoding categorical variables (Sex, Embarked)
* Selecting important features
* Splitting training data into Train / Validation

### âš¡ Model Training

Two powerful gradient boosting models are trained:

* **LightGBM**
* **XGBoost**

Their models are saved as `.pkl` files:

```
models/lgbm_model.pkl
models/xgb_model.pkl
```

### ğŸ“Š Model Evaluation

Evaluation includes:

* Accuracy
* Classification report
* Confusion matrix
* Side-by-side model comparison

Outputs are saved in:

```
output/reports/
    â”œâ”€â”€ lightgbm_evaluation.txt
    â”œâ”€â”€ xgboost_evaluation.txt
    â””â”€â”€ comparison_report.txt
```

### ğŸ§  Fully Automated Pipeline

Run everything (EDA â†’ Preprocessing â†’ Training â†’ Evaluation) using:

```bash
python src/main.py
```

The script ensures all folders exist and executes every step sequentially.

---

## ğŸ“‚ Project Structure

```
LGBM_&_XGBM/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Titanic_train.csv
â”‚   â””â”€â”€ Titanic_test.csv
â”‚
â”œâ”€â”€ models/                  # Saved models
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ graphs/              # EDA plots
â”‚   â””â”€â”€ reports/             # Evaluation reports
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Automated pipeline controller
â”‚   â”œâ”€â”€ eda.py               # EDA + graph generation
â”‚   â”œâ”€â”€ preprocess.py        # Data cleaning + encoding
â”‚   â”œâ”€â”€ train_models.py      # LightGBM & XGBoost training
â”‚   â””â”€â”€ evaluate.py          # Model evaluation + comparison
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Running the Project

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the full pipeline

```bash
python src/main.py
```

Everything will be generated automatically:

* Graphs â†’ `output/graphs/`
* Reports â†’ `output/reports/`
* Models â†’ `models/`

---

## ğŸ”§ Requirements

Main libraries:

* Python 3.10+
* pandas
* numpy
* seaborn
* matplotlib
* scikit-learn
* lightgbm
* xgboost
* joblib

All dependencies are included in `requirements.txt`.

---

## ğŸ¯ Purpose of the Project

This project is designed to be:

* **Beginner-friendly**
* **Industry-style**
* **Easy to maintain**
* **Clear and modular**
* **Useful for learning ML pipeline design**

It can be extended with:

* Hyperparameter tuning
* Cross-validation
* Additional models
* Deployment (Flask, FastAPI, Streamlit)

Just ask if you want any of these upgrades!

---

## ğŸ¤ Contributing

Feel free to fork the project and improve:

* Feature engineering
* Visualizations
* Model performance
* Documentation

Pull requests are welcome.

---

## ğŸ“„ License

This project is open-source and free to use for learning and development purposes.

---

**Happy Learning! ğŸš€**